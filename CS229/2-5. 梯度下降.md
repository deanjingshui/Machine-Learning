# Gradient descent

将函数代价最小化的方法



![](..\image\NG_梯度下降法.png)



:= 赋值运算符

$\alpha$ 学习速率 learning rate

注意：必须同时更新   $\theta_0$和 $\theta_1$



学习速率过小、过大

![](..\image\NG_学习速率.png)

fail to converge 无法收敛

diverge  甚至发散

![](..\image\NG_梯度下降_学习速率_2.png)

